% RGB <-> YUV
% Implementación
% [DONE] No queda claro por qué eligen calcular de a un sólo pixel.
% [DONE] No aclaran el tipo de desempaquetado que utilizan, o cómo dejan el registro (XMM1) como está al comienzo. Al final explican que esta operación la repiten 4 veces, pero no aclaran igualmente por qué decidieron desempaquetar a dw.
% [TODO] Hubiera quedado más claro si ponían los ejemplos de los registros que ejemplifican las máscaras justo debajo del texto que las nombra.
% [DONE] No cuentan de qué algoritmo están contando la implementación, si de RGB a YUV o al revés
% [DONE] En la explicación del valor repetido, escriben "El mismo no la correción del filtro" a qué se refieren?
% Análisis preliminar
% [DONE] Intenten ser lo más precisos posible con el detalle de la experimentación.
% [DONE] En qué plataforma se corrió? 
% [DONE] Dónde pusieron los mecanismos de medición? Al hacer una llamada al filtro? Al comenzar a ejecutar el tp2? Cuántas veces lo corrieron (exactamente)?
% [DONE] No identificaron cuál algoritmo es cuál en los gráficos
% Experimentación
% [DONE] La comparación con diferentes niveles de optimización en C tengo entendido que es parte del análisis preliminar.
% [TODO] Son dos experimentos simples (cambiar un par de instrucciones) o uno complejo, que involucre más cambio de código.
% [DONE] No identificaron cuál algoritmo es cuál en los gráficos

\section{Convertir entre RGB e YUV}

Los primeros filtros se tratan de conversores entre los espacios de colores RGB e YUV. Los mismos toman los valores de cada pixel y aplican transformaciones matriciales, tomando cada pixel individual como una matriz de sus componentes.

Esta transformación normalmente implica decimales, pero la misma está simplificada para funcionar con enteros entre 0 y 255 (que son los valores posibles de cada componente de un pixel).

Para la conversión RGB a YUV se aplican la siguiente transformación:

\begin{center}

	$
	\begin{bmatrix*}[l]
	Y = sature(((66 * R + 129 * G + 25 * B + 128) >> 8) + 16) \\
	U = sature(((-38 * R - 74 * G + 112 * B + 128) >> 8) + 128) \\
	V = sature(((112 * R - 94 * G - 18 * B + 128) >> 8) + 128)
	\end{bmatrix*}
	$

\end{center}

donde $sature$ representa una saturación sin signo, es decir, los valores fuera del rango [0,255] son acotados a los extremos del mismo.

Para la transformación inversa se utiliza la siguiente transformación:

\begin{center}

	$
	\begin{bmatrix*}[l]
	R = sature((298 * (Y - 16) + 409 * (V - 128) + 128) >> 8) \\
	G = sature((298 * (Y - 16) - 100 * (U - 128) - 208 * (V - 128) + 128) >> 8) \\
	B = sature((298 * (Y - 16) + 516 * (U - 128) + 128) >> 8)
	\end{bmatrix*}
	$

\end{center}

Cabe destacar que si bien los valores son correctos, los visores de imágenes siguen renderizando los colores como si correspondiesen a RGB, por lo que se genera el efecto visual que se muestra a continuación:


\begin{figure}[H]
	\centering
	$\vcenter{\hbox{\includegraphics[scale=1]{img/convert_RGB.jpg}}}$
	$\vcenter{\hbox{\LARGE$\xrightleftharpoons[\text{YUVtoRGB}]{\text{RGBtoYUV}}$}}$
	$\vcenter{\hbox{\includegraphics[scale=1]{img/convert_YUV.jpg}}}$
\end{figure}


\subsection{Implementación}

La solución implica recorrer la imagen completa aplicando la transformación a cada pixel de manera individual.

La implementación en C es relativamente trivial: se aplica la transformación correspondiente a cada componente de manera individual. En el caso de la transformación YUV a RGB existen algunos valores que podemos reutilizar, pero los demás cálculos se realizan como se indica en el problema.

Para la implementación en ASM definimos un par de constantes. La idea es que cada una represente una fila de la matriz de transformación. De esta manera, podemos calcular los 3 componentes fuente de cada componente destino en simultaneo.

Para los siguientes ejemplos se utiliza el filtro RGB2YUV, pero la implementación del filtro inverso es muy similar.

Primero, se definen 3 máscaras. Cada una se utilizará para crear una de las componentes finales:

\begin{center}
	\xmm{9} \xmmDoubleWordSmall{66}{129}{25}{0}

	\xmm{10} \xmmDoubleWordSmall{-38}{-74}{112}{0}

	\xmm{11} \xmmDoubleWordSmall{112}{-94}{-18}{0}
\end{center}

Ya que contamos con registros de 128 bits y cada pixel mide 32 bits de ancho (RGBA), podemos cargar 4 pixeles de la memoria por iteración. Esto permite reducir el impacto de los accesos a memoria y los saltos condicionales.

No obstante, los mismos son desempaquetados para ocupar los registros XMM de manera individual, con cada una de sus componentes en tamaño doubleword (32 bits). Esto es porque los valores que multiplicamos y sumamos pueden exceder el límite de una word, y perderíamos precisión o retornaríamos valores inválidos. Esto también se refleja en la implementación C, donde consideramos utilizar \texttt{unsigned short}, de 16 bits, pero esto generaba demasiados errores y nos vimos forzados a usar \texttt{unsigned int}, de 32 bits.

Por lo tanto, la lógica de procesamiento de cada pixel se ve repetida 4 veces, una por pixel por iteración. Sin embargo, tenemos la garantía que la imagen tendrá como ancho un múltiplo de 4, por lo que esto no presenta un problema.

\begin{center}

	\xmm{0} \xmmDoubleWordSmall{0}{0}{0}{0}

	\xmm{4} \xmmDoubleWordSmall{P1}{P2}{P3}{P4}

	\xmm{2} $\leftarrow$ \xmm{4}

	\texttt{PUNPCKHBW} \xmm{2}, \xmm{0} \hfill

	\xmm{2} \xmmWord{$P1_R$}{$P1_G$}{$P1_B$}{0}{$P2_R$}{$P2_G$}{$P2_B$}{0}

	\xmm{1} $\leftarrow$ \xmm{2}

	\texttt{PUNPCKHWD} \xmm{1}, \xmm{0} \hfill

	\texttt{PUNPCKLWD} \xmm{2}, \xmm{0} \hfill

	\xmm{1} \xmmDoubleWordSmall{$P1_R$}{$P1_G$}{$P1_B$}{0}

	\xmm{2} \xmmDoubleWordSmall{$P2_R$}{$P2_G$}{$P2_B$}{0}

	$\vdots$

	(se omiten instrucciones por su similitud)

	\xmm{3} \xmmDoubleWordSmall{$P3_R$}{$P3_G$}{$P3_B$}{0}

	\xmm{4} \xmmDoubleWordSmall{$P4_R$}{$P4_G$}{$P4_B$}{0}

\end{center}

Cada pixel es copiado 3 veces (en su registro original y a los registros XMM14 y XMM15), una por componente destino (en este caso, Y, U y V). Luego, se multiplican estas copias del pixel por la máscara correspondiente:

\begin{center}

	\texttt{PMULLD} \xmm{14}, \xmm{9} \hfill

	\xmm{14} \xmmDoubleWordSmall{$Y'_R$}{$Y'_G$}{$Y'_B$}{0}

	\texttt{PMULLD} \xmm{15}, \xmm{10} \hfill

	\xmm{15} \xmmDoubleWordSmall{$U'_R$}{$U'_G$}{$U'_B$}{0}

	\texttt{PMULLD} \xmm{1}, \xmm{11} \hfill

	\xmm{1} \xmmDoubleWordSmall{$V'_R$}{$V'_G$}{$V'_B$}{0}
	
\end{center}

Por último, estos valores intermedios se suman horizontalmente para crear las componentes finales:

\begin{center}

	\texttt{PHADDD} \xmm{15}, \xmm{14} \hfill

	\xmm{15} \xmmDoubleWordSmall{$Y'_{R+G}$}{$Y'_B$}{$U'_{R+G}$}{$U'_B$}

	\texttt{PHADDD} \xmm{1}, \xmm{1} \hfill

	\xmm{1} \xmmDoubleWordSmall{$V'_{R+G}$}{$V'_B$}{$V'_{R+G}$}{$V'_B$}

	\texttt{PHADDD} \xmm{1}, \xmm{15} \hfill

	\xmm{1} \xmmDoubleWordSmall{$Y'$}{$U'$}{$V'$}{$V'$}

\end{center}

Como se puede ver, al sumar se genera un valor duplicado al final. El mismo se genera porque las imagenes tienen 3 componentes y \texttt{PHADDD} toma siempre 2 parámetros. Esto no afecta la correción del filtro, ya que no estamos trabajando con el componente alfa y el mismo puede ser descartado.

Por último, estos componentes se denotan con $'$ porqe los mismos no son los valores finales: debemos aplicar 2 sumas y un shift a todos los componentes para finalizar la conversión. Para las sumas utilizamos nuevamente constantes precargadas en un registro XMM.

Al finalizar la conversión, los pixeles son reempaquetados para ser guardados en una sola operación. El empaquetado es sin signo, de manera que cualquier valor por encima del máximo es acotado al máximo de dicha componente (\texttt{0xFF}):

\begin{center}
	\xmm{1} \xmmDoubleWordSmall{$P1_Y$}{$P1_U$}{$P1_V$}{0}

	\xmm{2} \xmmDoubleWordSmall{$P2_Y$}{$P2_U$}{$P2_V$}{0}

	\xmm{3} \xmmDoubleWordSmall{$P3_Y$}{$P3_U$}{$P3_V$}{0}

	\xmm{4} \xmmDoubleWordSmall{$P4_Y$}{$P4_U$}{$P4_V$}{0}

	\texttt{PACKUSDW} \xmm{2}, \xmm{1} \hfill

	\xmm{2} \xmmWord{$P1_Y$}{$P1_U$}{$P1_V$}{0}{$P2_Y$}{$P2_U$}{$P2_V$}{0}

	\texttt{PACKUSDW} \xmm{4}, \xmm{3} \hfill

	\xmm{4} \xmmWord{$P3_Y$}{$P3_U$}{$P3_V$}{0}{$P4_Y$}{$P4_U$}{$P4_V$}{0}

	\texttt{PACKUSWB} \xmm{4}, \xmm{2} \hfill

	\xmm{4} \xmmDoubleWordSmall{P1}{P2}{P3}{P4}
\end{center}

(notese que en este contexto $Pi$ no representa el mismo pixel de entrada sino su correspondiente post-conversión)

Un detalle importante que aplica a este filtro es la independencia entre todos los pixeles, y la independencia de los mismos con respecto a su posición. Este detalle nos permite recorrer la imagen no como una matriz de pixeles sino como una lista continua de tamaño $w \times h$.

\subsection{Análisis preliminar}

Para realizar un análisis preliminar del rendimiento de los algoritmos, debimos medir los tiempos de ejecución de los mismos. Por claridad, unificamos el criterio utilizados para las mediciones a lo largo de todo el trabajo práctico. Los detalles de dicho critero se encuentran en el apéndice correspondiente.

Como ambos filtros son muy similares, los podemos comparar lado a lado:

\begin{center}
	\includegraphics[scale=0.5]{img/conversores_CvsASMvsO3.png}
\end{center}

Por un lado, se puede notar una diferencia enorme en la performance del algoritmo escrito en C contra el escrito en ASM. Al compilar con optimizaciones, la brecha de performance baja drásticamente. Sospechamos que esto se debe a un uso más exhaustivo de los registros en lugar de acceder constantemente a memoria. Sin embargo, se puede ver que el algoritmo escrito con instrucciones SIMD sigue siendo más óptimo (hasta casi 60\% del tiempo, 2090676 en ASM vs 3377772 en C con \texttt{-O3}). Si bien la diferencia es visiblemente menor, y nuestras mediciones contaron con un poco de ruido, la diferencia porcentual es visible y relevante.

Por otro lado, se puede ver que en O0 el conversor YUV a RGB performa mejor que su contraparte RGB a YUV (con una diferencia de más de 10\%). Esto posiblemente se deba a ciertas operaciones que como mencionamos se repiten, y por ende podemos pre-calcular y reutilizar valores intermedios.

\subsection{Experimentación}

A modo de experimentación, decidimos probar con distintas imágenes con distintas proporciones. Los aspectos generales de la experimentación se encuentran detallado en los apéndices.

\begin{center}
	\includegraphics[scale=0.5]{img/conversores_blanco.png}
\end{center}

De cara a la experimentación, esperábamos que los algoritmos fuesen agnósticos a la mayoría de los detalles de la entrada. Sin embargo, al probar utilizando un bitmap blanco, podemos ver que la saturación de las componentes tiene un efecto visible en el tiempo de ejecución de los filtros. No solo eso, el bitmap afecta de manera positiva a la implementación en C, mientras que impacta de forma negativa a su contraparte SSE.

Nuestra teoría frente a esto es que la saturación puede ser optimizada en el caso de C (se pueden evitar algunos cálculos si se ve que el resultado estará saturado). Por otro lado, en ASM el procesador detecta que los componentes generan overflow y debe realizar el ajuste necesario para conservar un valor válido y saturado.